{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run this before making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "class Args(argparse.Namespace):\n",
    "    # General settings\n",
    "    annotation_path = './data/annotations/all_annotations.json'\n",
    "    images_path = './data/images'\n",
    "    n_to_visualize = 0 \n",
    "    match_prompt_img=False\n",
    "    timeseries = None\n",
    "\n",
    "    # Experiment settings\n",
    "    model = 'SegGPT'\n",
    "    location = '1'\n",
    "    batch_size = 5\n",
    "    remove_posthoc = True\n",
    "    prompt_imgs = [4]\n",
    "    remove_input = False\n",
    "    n_patches = 1\n",
    "\n",
    "    # SegGPT\n",
    "    binary_mask_cutoff = 0.8\n",
    "\n",
    "    # PerSAM\n",
    "    min_feature_sim = 0.15\n",
    "    persam_training = False\n",
    "\n",
    "    # YOLO\n",
    "    yolo_test_path = None\n",
    "    yolo_model_path = './models/pretrained_yolo_models/best.pt'\n",
    "    conf_threshold = 0.25\n",
    "\n",
    "args=Args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset class balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mask counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "from dataset import get_gt_masks\n",
    "\n",
    "label_counter = {}\n",
    "for location in tqdm(os.listdir('./data/images')):\n",
    "    all_labels = []\n",
    "    image_folder = f'./data/images/{location}'\n",
    "    annotations = get_gt_masks('./data/annotations/all_annotations.json', image_folder)\n",
    "\n",
    "    for file in os.listdir(image_folder):\n",
    "\n",
    "        _, labels = annotations[file]\n",
    "        all_labels += labels\n",
    "    \n",
    "    label_counter[location] = Counter(all_labels)\n",
    "\n",
    "label_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counters in correct format\n",
    "labels = ['floating_trash_in_system', 'floating_trash_outside_system', 'water', 'barrier']\n",
    "counter_vis = {}\n",
    "for location, counter in label_counter.items():\n",
    "    for l in labels:\n",
    "        if l not in counter.keys():\n",
    "            counter[l] = 0\n",
    "\n",
    "    counter_vis[location] = {\n",
    "        'In system' : counter['floating_trash_in_system'],\n",
    "        'Out system' : counter['floating_trash_outside_system'],\n",
    "        'Barrier' : counter['barrier'],\n",
    "        'Water' : counter['water']\n",
    "    }\n",
    "\n",
    "# Collect counts across locations\n",
    "overall_counter = {x: 0 for x in counter_vis['1'].keys()}\n",
    "for counter in counter_vis.values():\n",
    "    for key in overall_counter.keys():\n",
    "        overall_counter[key] += counter[key]    \n",
    "\n",
    "counter_vis['Overall'] = overall_counter\n",
    "df = pd.DataFrame.from_dict(counter_vis).T\n",
    "df['total'] = df.sum(axis=1)\n",
    "for c in df.columns:\n",
    "    if c == 'total':\n",
    "        continue\n",
    "\n",
    "    df[c] = df[c]*100/df['total']\n",
    "df.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pixel counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from dataset import get_gt_masks\n",
    "\n",
    "full_labels = ['floating_trash_in_system', 'floating_trash_outside_system', 'barrier', 'water']\n",
    "pixel_counter = {}\n",
    "for location in tqdm(os.listdir('./data/imagese')):\n",
    "    image_folder = f'./data/images/{location}'\n",
    "    annotations = get_gt_masks('./data/annotations/all_annotations.json', image_folder)\n",
    "\n",
    "    pixel_counter[location] = {x: 0 for x in full_labels}\n",
    "\n",
    "    for file in os.listdir(image_folder):\n",
    "        masks, labels = annotations[file]\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        for l in full_labels:\n",
    "            class_masks = masks[labels == l]\n",
    "            pixel_counter[location][l] += torch.sum(class_masks).item()\n",
    "\n",
    "pixel_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect counts across locations\n",
    "overall_counter = {x: 0 for x in full_labels}\n",
    "for label in overall_counter.keys():   \n",
    "    for location in pixel_counter.keys():\n",
    "        overall_counter[label] += pixel_counter[location][label]\n",
    "pixel_counter['Overall'] = overall_counter\n",
    "\n",
    "df = pd.DataFrame.from_dict(pixel_counter).T\n",
    "df['total'] = df.sum(axis=1)\n",
    "for c in df.columns:\n",
    "    if c == 'total':\n",
    "        continue\n",
    "\n",
    "    df[c] = df[c]*100/df['total']\n",
    "df.rename(columns={'floating_trash_in_system': 'in-system', 'floating_trash_outside_system': 'out-system'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bin GT masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from dataset import get_gt_masks\n",
    "from torchvision.transforms.functional import resize\n",
    "\n",
    "location_bins = {\n",
    "'1' : np.array([0.125, 0.25])*1e6,\n",
    "'2' : np.array([0.1, 0.2])*1e6,\n",
    "'3' : np.array([0.1, 0.2])*1e6,\n",
    "'4' : np.array([0.15, 0.3])*1e6,\n",
    "'5' : np.array([0.005, 0.02])*1e6,\n",
    "'6' : np.array([0.15, 0.3])*1e6,\n",
    "}\n",
    "for gt_file in os.listdir('./data/combined_gt_masks'):\n",
    "    location = gt_file.replace('.pt', '')\n",
    "    gt_mask = torch.load(f'./data/combined_gt_masks/{gt_file}')\n",
    "    total_px = torch.sum(gt_mask)\n",
    "\n",
    "    print(location, [round((x*100/total_px).item(),1) for x in location_bins[location]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for location in os.listdir('data/imagese'):\n",
    "    location_folder = './data/imagese/' + location\n",
    "    gt_masks = get_gt_masks('./data/annotations/all_annotations.json', location_folder)\n",
    "\n",
    "    gt_mask_sizes = []\n",
    "    for file in os.listdir(location_folder):\n",
    "        masks, labels = gt_masks[file]\n",
    "\n",
    "        in_system_ids = np.where(np.array(labels) == 'floating_trash_in_system')\n",
    "        masks = masks[in_system_ids]\n",
    "        \n",
    "        if location in ['5', '6']:\n",
    "            masks = resize(masks, (1944, 2592))\n",
    "\n",
    "        mask_size = torch.sum(masks)\n",
    "        gt_mask_sizes.append(mask_size.item())\n",
    "\n",
    "    gt_mask_sizes = np.array(gt_mask_sizes)\n",
    "    small = np.sum(gt_mask_sizes <= location_bins[location][0])\n",
    "    medium = np.sum((gt_mask_sizes > location_bins[location][0]) & (gt_mask_sizes <= location_bins[location][1]))\n",
    "    large = np.sum(gt_mask_sizes > location_bins[location][1])\n",
    "\n",
    "    print(small, medium, large)\n",
    "\n",
    "    fig, axs = plt.subplots(1,2, figsize=(10,5))\n",
    "    axs[0].hist(gt_mask_sizes)\n",
    "    axs[1].bar(['small', 'medium', 'large'], [small, medium, large])\n",
    "    plt.title(location)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create post-hoc removal masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.io import read_image\n",
    "from visualization import draw_ann\n",
    "\n",
    "for location in os.listdir('./data/images'):\n",
    "    if location != '5':\n",
    "        continue\n",
    "\n",
    "    image_folder = f'./data/images/{location}'\n",
    "    annotations = get_gt_masks('./data/annotations/all_annotations.json', image_folder)\n",
    "\n",
    "    all_gt_masks = []\n",
    "    for masks, _ in tqdm(annotations.values()):\n",
    "        masks = resize(masks, (1944, 2592))\n",
    "        masks = torch.sum(masks, dim=0).unsqueeze(0)\n",
    "        all_gt_masks.append(masks)\n",
    "\n",
    "    combined_masks = torch.sum(torch.concat(all_gt_masks, dim=0), dim=0)\n",
    "    combined_masks = combined_masks > 0\n",
    "\n",
    "    first_img = os.listdir(image_folder)[0]\n",
    "    image = read_image(f'{image_folder}/{first_img}')\n",
    "    image = resize(image, (1944,2592))\n",
    "    annotated = draw_ann(image, combined_masks.unsqueeze(0), int_colors=[[255, 0, 110]])\n",
    "\n",
    "    plt.imshow(annotated)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    torch.save(combined_masks, f'./data/combined_gt_masks/{location}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize prompt images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms.functional import resize, to_pil_image\n",
    "import torch\n",
    "\n",
    "from dataset import get_gt_masks\n",
    "from visualization import draw_ann\n",
    "from utils import get_int_from_label\n",
    "from dataset import finetuning_images\n",
    "\n",
    "mask_colors = [[255, 0, 110], [131, 56, 236]]\n",
    "imgs = {x: [] for x in finetuning_images.keys()}\n",
    "\n",
    "for location in finetuning_images.keys():\n",
    "    image_folder = f'./data/images/{location}'\n",
    "    annotations = get_gt_masks('./data/annotations/all_annotations.json', image_folder)\n",
    "\n",
    "    for i, (img_id, mask_ids)  in enumerate(finetuning_images[location].items()):\n",
    "        img_path = f'{image_folder}/{img_id}'\n",
    "        original_image = read_image(img_path) \n",
    "        masks, labels = annotations[img_id]\n",
    "        \n",
    "        # Resize images from two locations\n",
    "        if location in ['5', '6']:\n",
    "            original_image = resize(original_image, (1944, 2592))\n",
    "            masks = resize(masks, (1944, 2592))\n",
    "\n",
    "        # Go from string to int labels\n",
    "        labels = torch.Tensor([get_int_from_label(l) for l in labels])\n",
    "        in_system = masks[labels==0] > 0\n",
    "\n",
    "        selected_masks = in_system[mask_ids]\n",
    "        annotated = draw_ann(original_image, selected_masks, mask_colors)\n",
    "        imgs[location].append(annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6, 5, figsize=(20,20))\n",
    "for i, loc in enumerate(imgs.keys()):\n",
    "    ax = axs[i]\n",
    "    [a.axis('off') for a in ax]\n",
    "\n",
    "    for j, img in enumerate(imgs[loc]):\n",
    "        ax[j].imshow(img)\n",
    "\n",
    "    ax[2].set_title(loc.replace('_', ' '))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timeseries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from visualization import draw_ann\n",
    "from tqdm import tqdm\n",
    "from main import main\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dt(string):\n",
    "    date = string.split('_')[1]\n",
    "    time = string.split('_')[2]\n",
    "    dt = f'{date[:4]} {date[4:6]} {date[6:]} {time[:2]} {time[2:4]}'\n",
    "    dt = datetime.strptime(dt, '%Y %m %d %H %M')\n",
    "    return dt \n",
    "\n",
    "def create_timeseries(folder, model, gif=False, graph=False):\n",
    "    args.timeseries = folder\n",
    "    args.location = args.timeseries.split('/')[-1].split('_')[0]\n",
    "    args.model = model\n",
    "\n",
    "    assert model in ['SegGPT', 'YOLO']\n",
    "\n",
    "    if model == 'SegGPT':\n",
    "        args.binary_mask_cutoff = 0.8 if args.location == '1' else 0.95\n",
    "        args.prompt_imgs = [4] if args.location == '1' else [3]\n",
    "        args.yolo_model_path = None\n",
    "\n",
    "    if model == 'YOLO':\n",
    "        args.binary_mask_cutoff = 0.8\n",
    "        args.prompt_imgs = []\n",
    "        args.yolo_model_path = './models/pretrained_yolo_models/best.pt'\n",
    "\n",
    "    # Make predictions\n",
    "    output = main(args)\n",
    "\n",
    "    # Create gif from timeseries data\n",
    "    if gif:\n",
    "        images = []\n",
    "        for o in tqdm(output):\n",
    "            img, mask, id = o['images'], o['predicted_masks'], o['img_id']\n",
    "\n",
    "            # Annotate mask\n",
    "            mask = torch.sum(mask, dim=0).unsqueeze(0) > 0\n",
    "            ann = draw_ann(img, mask, int_colors=[[255, 0, 110]])\n",
    "\n",
    "            # Put time\n",
    "            dt_string = datetime.strftime(get_dt(id), '%Y-%m-%d %H:%M')\n",
    "            ann_draw = ImageDraw.Draw(ann)\n",
    "            ann_draw.text((0,0), dt_string, fill=(0,0,0), font_size=100)\n",
    "            ann = ann_draw._image\n",
    "            images.append(ann)\n",
    "        images[0].save(f'gifs/{ts}_{model}.gif', format='GIF', append_images=images, save_all=True, duration=300, loop=0)\n",
    "\n",
    "    # Create graph\n",
    "    if graph:\n",
    "        pred_pixels = [torch.sum(x['predicted_masks']) for x in output]\n",
    "        dts = [get_dt(x) for x in os.listdir(args.timeseries)]\n",
    "        df = pd.DataFrame.from_dict({'Time': dts, 'Predicted Pixels': [x.item() for x in pred_pixels]})\n",
    "        df.plot(x='Time')\n",
    "        plt.title(f'{ts.replace(\"_\", \" \")} - {args.model}')\n",
    "        plt.show()\n",
    "\n",
    "# Insert timeseries data here\n",
    "timeseries = os.listdir('./data/timeseries')\n",
    "for ts in timeseries:\n",
    "    for model in ['YOLO', 'SegGPT']:\n",
    "        create_timeseries(ts, model, gif=False, graph=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "river-segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
